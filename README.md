# Dissertation
My master Dissertation in NTU
* It is an NLP related dissertation
* The topic is Online News Analytics based on AI Techniques
* The main content is to collect a natural disaster dataset and perform news classification tasks on different feature representation methods and classifier

## Usage

* ğŸ“ƒ Datasetï¼š

  â€‹	BBC_news is an dataset contains news from bbc website.

  â€‹	disaster_news_dataset.csv is the collected dataset about natrual disaster.

  â€‹	path:  code/dataset/disaster_news_dataset.csv

  â€‹	content:

  â€‹    <img src="image/image-20211024131756544.png" alt="image-20211024131756544" style="zoom:30%;" />

  â€‹	Distribution:

  <img src="image/image-20211024131937924.png" alt="image-20211024131937924" style="zoom:30%;" />

  <img src="image/image-20211024131952624.png" alt="image-20211024131952624" style="zoom:30%;" />

  <img src="image/image-20211024132019640.png" alt="image-20211024132019640" style="zoom:30%;" />

  â€‹		data_extraction.py:  is used to separate the dataset into test_set,trainning_set and validation_set. you might have to change the loading path before you use.

  â€‹		build_w2v.py: is to transfer the word2vec to the type that could be used in model.  **<u>You should download GoogleNews-vectors-negative300.bin before using this py</u>**

* ğŸ•¸ï¸Bow+LR

  â€‹	path: code/bow+LR

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

* ğŸ•¸ï¸Bow+SVM

  â€‹	path: code/bow+SVM

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

* ğŸ•¸ï¸Bow+Feed-forward

  â€‹	path: code/bow+feedforward

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

<img src="image/image-20211211003809154.png" alt="image-20211211003809154" style="zoom:50%;" />

* ğŸ•¸ï¸TF-IDF+LR

  â€‹	path: code/bow+LR

  â€‹	modify the code to use TF-IDF

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

* ğŸ•¸ï¸TF-IDF+SVM

  â€‹	path: code/bow+SVM

  â€‹	modify the code to use TF-IDF

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

* ğŸ•¸ï¸TF-IDF+Feed-forward

  â€‹	path: code/bow+feedforward

  â€‹	modify the code to use TF-IDF

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

<img src="image/image-20211211003846660.png" alt="image-20211211003846660" style="zoom:50%;" />

* ğŸ•¸ï¸LDA+LR

  â€‹	path: code/LDA+LR

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

* ğŸ•¸ï¸LDA+SVM

  â€‹	path: code/LDA+SVM

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

* ğŸ•¸ï¸LDA+Feed-forward

  â€‹	path: code/LDA+feedforward

  â€‹	train and test command : **python3 main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

<img src="image/image-20211211003943614.png" alt="image-20211211003943614" style="zoom:50%;" />

<img src="image/image-20211211004128139.png" alt="image-20211211004128139" style="zoom:50%;" />

* ğŸ•¸ï¸ Text-CNNï¼š

  â€‹	pathï¼šcode/text_cnn

  â€‹	train and test command : **python main.py** 

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

  â€‹	you can modify the code to use non-pretrain embedding / word2vec embedding /glove embedding	

  â€‹	**you should download glove.840B.300d.txt and put it in correct path before you use it.**

* ğŸ•¸ï¸ LSTMï¼š

  â€‹	path: code/lstm

  â€‹	train and test command : **python main.py** 	

  â€‹	test criteria is: accuracy, precise,recall,f1-score.

  â€‹	you can also modify the code to use non-pretrain embedding / word2vec embedding /glove embedding	    

  â€‹	when using non-pretrain embedding, you might have to modify the setting.py and model.py

  â€‹	**you should download glove.840B.300d.txt and put it in correct path before you use it.**

* ğŸ•¸ï¸ Transformerï¼š

  â€‹	based on huggingface transformer

  â€‹	path: code/transformer

  â€‹	train and test command: 

  ```
  export TASK_NAME=test_classifify
  python run_glue.py \
    --model_name_or_path bert-base-cased \
    --train_file ../dataset/training_set.csv \
    --validation_file ../dataset/validation_set.csv \
    --test_file ../dataset/test_set.csv \
    --do_train \
    --do_eval \
    --do_predict \
    --max_seq_length 256 \
    --per_device_train_batch_size 8 \
    --learning_rate 2e-5 \
    --num_train_epochs 32 \
    --overwrite_output_dir True \
    --output_dir ./$TASK_NAME/
  ```

  use Bert-base-case model to perform classification tasks;

* ğŸŒŸOther:

  â€‹	these models will be train 10 times to evaluate the mean performance by default, you can modify the code to change.

  

* ğŸ“– Resultï¼š

  <img src="image/image-20211024135421500.png" alt="image-20211024135421500" style="zoom:50%;" />

  <img src="image/image-20211211004041421.png" alt="image-20211211004041421" style="zoom:50%;" />

  <img src="image/image-20211024135439948.png" alt="image-20211024135439948" style="zoom:50%;" />

  <img src="image/image-20211211004108314.png" alt="image-20211211004108314" style="zoom:50%;" />