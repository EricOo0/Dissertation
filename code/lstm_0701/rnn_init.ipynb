{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understand the lstm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 100])\n",
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 100])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "net = nn.LSTM(100, 128) #Assume only one layer\n",
    "print(net.weight_ih_l0.shape)# (4*hidden_size, input_size)\n",
    "print(net.weight_hh_l0.shape)#(4*hidden_size, hidden_size)\n",
    "print(net.bias_ih_l0.shape)#(4*hidden_size)\n",
    "print(net.bias_hh_l0.shape)#(4*hidden_size)\n",
    "w_ii, w_if, w_ic, w_io = net.weight_ih_l0.chunk(4, 0) #每个都是(hidden_size,input_size)\n",
    "print(w_ii.shape)\n",
    "w_hi, w_hf, w_hc, w_ho = net.weight_hh_l0.chunk(4, 0) #每个都是(hidden_size,hidden_size)\n",
    "print(w_hi.shape)\n",
    "b_ii, b_if, b_ic, b_io = net.bias_ih_l0.chunk(4, 0) #每个都是(hidden_size)\n",
    "print(b_ii.shape)\n",
    "b_hi, b_hf, b_hc, b_ho = net.bias_hh_l0.chunk(4, 0) #每个都是(hidden_size)\n",
    "print(b_hi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可以对不同的gate进行自定义的初始化\n",
    "但一般建议:\n",
    "* 将gates的权重正交初始化， \n",
    "* forget gate的bias初始值(LSTM时)取1.0\n",
    "\n",
    "另外注意：W chunk之后的各个部分其实还在原来的内存区域，所以**对各个部分的初始化会直接反应到整个W中的相应区域**,不需要去反过来赋值或重组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0626,  0.0224,  0.0790,  ..., -0.0398,  0.0043, -0.0535],\n",
       "        [-0.0717, -0.0532,  0.0171,  ..., -0.0884, -0.0362, -0.0370],\n",
       "        [-0.0738,  0.0284, -0.0317,  ...,  0.0549,  0.0575, -0.0075],\n",
       "        ...,\n",
       "        [ 0.0065,  0.0557, -0.0182,  ...,  0.0415,  0.0431, -0.0754],\n",
       "        [-0.0809, -0.0491,  0.0783,  ...,  0.0447, -0.0278, -0.0652],\n",
       "        [-0.0777, -0.0701, -0.0436,  ..., -0.0006,  0.0531, -0.0725]],\n",
       "       grad_fn=<SplitBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#默认均匀随机初始化\n",
    "w_if"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0541,  0.0111,  0.1698,  ..., -0.0180, -0.2143, -0.1415],\n",
       "        [-0.0221,  0.0007,  0.0994,  ..., -0.0352,  0.1932, -0.1889],\n",
       "        [ 0.0181,  0.0853,  0.0252,  ...,  0.0795, -0.0963, -0.0718],\n",
       "        ...,\n",
       "        [-0.1255,  0.1350, -0.0790,  ..., -0.0284, -0.0436, -0.0458],\n",
       "        [ 0.0839,  0.1167, -0.0585,  ...,  0.0896, -0.0150, -0.0669],\n",
       "        [-0.0345, -0.1474, -0.1191,  ..., -0.0168,  0.0529, -0.0357]],\n",
       "       grad_fn=<SplitBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nn.init.orthogonal_(self.rnn.weight_ih_l0) #可以直接对所有的gates正交初始化\n",
    "nn.init.orthogonal_(w_if)#orthogonal initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0541,  0.0111,  0.1698,  ..., -0.0180, -0.2143, -0.1415],\n",
      "        [-0.0221,  0.0007,  0.0994,  ..., -0.0352,  0.1932, -0.1889],\n",
      "        [ 0.0181,  0.0853,  0.0252,  ...,  0.0795, -0.0963, -0.0718],\n",
      "        ...,\n",
      "        [-0.1255,  0.1350, -0.0790,  ..., -0.0284, -0.0436, -0.0458],\n",
      "        [ 0.0839,  0.1167, -0.0585,  ...,  0.0896, -0.0150, -0.0669],\n",
      "        [-0.0345, -0.1474, -0.1191,  ..., -0.0168,  0.0529, -0.0357]],\n",
      "       grad_fn=<SplitBackward>)\n"
     ]
    }
   ],
   "source": [
    "w_ii, w_if_new, w_ic, w_io = net.weight_ih_l0.chunk(4, 0)\n",
    "print(w_if_new)#自动跟着改变，因为内存相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.8035e-02, -6.2069e-02,  1.4225e-02,  5.8883e-02, -8.4355e-02,\n",
      "        -1.8253e-02, -7.4605e-02, -4.4818e-02,  5.3677e-02,  6.9491e-02,\n",
      "        -4.7941e-02,  7.7492e-02, -5.7955e-02, -4.4675e-02, -3.8080e-02,\n",
      "         1.4237e-02, -1.0186e-02,  3.6231e-02, -2.5299e-02, -4.5784e-02,\n",
      "         5.6310e-02,  7.6527e-02, -1.2838e-02, -6.4982e-02,  2.9514e-02,\n",
      "         1.6034e-02, -3.9057e-02, -4.2777e-02, -3.9535e-02,  3.3162e-03,\n",
      "         2.7241e-02,  8.4419e-03,  6.4859e-02,  2.7500e-02, -6.5306e-02,\n",
      "        -5.3536e-02, -1.3858e-05,  4.7566e-02,  2.8924e-03,  5.5258e-02,\n",
      "         2.5063e-02,  5.8828e-02,  7.7831e-02, -2.4024e-02,  4.7317e-02,\n",
      "         9.2443e-03,  1.6396e-02,  3.6019e-02,  2.2863e-02,  4.2083e-02,\n",
      "         1.5684e-02, -8.6889e-02, -3.1551e-02, -7.0145e-03,  3.7256e-02,\n",
      "        -6.9480e-02,  4.0860e-02, -3.5777e-03, -1.3850e-02,  6.3861e-02,\n",
      "        -8.0556e-02,  4.5408e-02,  3.3153e-02, -4.4095e-02,  3.2675e-03,\n",
      "        -6.7233e-03,  2.4190e-02,  5.4704e-02, -5.0567e-02,  7.3287e-02,\n",
      "        -2.8379e-02, -5.7663e-02, -1.2876e-02, -1.1099e-02,  8.7590e-02,\n",
      "         7.1316e-02,  5.2014e-02,  6.5233e-02, -2.4122e-03, -3.4303e-02,\n",
      "        -2.1941e-02, -8.0727e-03,  5.7554e-03,  1.6430e-02,  4.1654e-02,\n",
      "        -5.1236e-02, -7.7273e-02, -3.3203e-02, -2.5631e-02,  5.9936e-02,\n",
      "         8.7689e-02,  5.5141e-02, -3.4774e-02,  1.1059e-02,  6.3323e-02,\n",
      "        -4.9662e-02, -7.6970e-02, -6.2205e-02, -7.2543e-02,  3.5978e-02,\n",
      "        -4.6628e-02,  4.7751e-02, -1.6160e-05, -6.4942e-02, -8.1835e-02,\n",
      "        -6.8171e-04,  4.1947e-02,  6.4704e-02, -1.9692e-02, -2.9170e-02,\n",
      "         1.8880e-05, -3.6639e-02,  3.2360e-02, -4.4872e-02,  7.0802e-02,\n",
      "        -6.3081e-02, -6.1962e-02, -2.1028e-02, -2.2839e-02, -5.8272e-02,\n",
      "        -3.1143e-02, -5.5546e-02,  2.2522e-02,  2.5285e-02,  6.1461e-02,\n",
      "        -6.6329e-02,  3.9856e-02, -1.2622e-02], grad_fn=<SplitBackward>)\n",
      "tensor([-0.0368, -0.0177,  0.0424,  0.0123,  0.0697,  0.0217, -0.0547, -0.0568,\n",
      "        -0.0028,  0.0435, -0.0207,  0.0278, -0.0599,  0.0291, -0.0193,  0.0727,\n",
      "        -0.0830,  0.0685,  0.0563,  0.0216, -0.0200, -0.0513,  0.0141, -0.0736,\n",
      "         0.0740, -0.0478,  0.0282,  0.0469,  0.0082,  0.0506, -0.0289,  0.0578,\n",
      "         0.0110,  0.0310, -0.0543,  0.0502, -0.0112,  0.0710,  0.0624, -0.0157,\n",
      "        -0.0042,  0.0187, -0.0631,  0.0346,  0.0810, -0.0711, -0.0534, -0.0525,\n",
      "        -0.0801,  0.0134, -0.0530,  0.0801,  0.0701, -0.0185, -0.0003,  0.0800,\n",
      "         0.0322, -0.0211, -0.0527,  0.0531, -0.0303,  0.0307, -0.0260,  0.0732,\n",
      "         0.0159,  0.0693,  0.0066,  0.0601,  0.0353, -0.0350, -0.0029,  0.0169,\n",
      "        -0.0037, -0.0443,  0.0558, -0.0748,  0.0162, -0.0490,  0.0433, -0.0091,\n",
      "         0.0678,  0.0658,  0.0157, -0.0554, -0.0085,  0.0630,  0.0119,  0.0634,\n",
      "        -0.0721,  0.0729,  0.0726,  0.0755, -0.0440,  0.0224, -0.0802,  0.0009,\n",
      "        -0.0185, -0.0512,  0.0243, -0.0562,  0.0203, -0.0633, -0.0574,  0.0355,\n",
      "         0.0077, -0.0590, -0.0811, -0.0808,  0.0537, -0.0825,  0.0773, -0.0396,\n",
      "        -0.0043,  0.0826,  0.0510,  0.0660, -0.0800, -0.0072, -0.0006,  0.0148,\n",
      "        -0.0807,  0.0484, -0.0108,  0.0464,  0.0172,  0.0386, -0.0131,  0.0882],\n",
      "       grad_fn=<SplitBackward>)\n"
     ]
    }
   ],
   "source": [
    "#观察forget gate bias的默认初始化\n",
    "print(b_if)\n",
    "print(b_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], grad_fn=<SplitBackward>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], grad_fn=<SplitBackward>)\n"
     ]
    }
   ],
   "source": [
    "#forget gate的bias初始值(LSTM时)取1.0\n",
    "nn.init.ones_(b_if) #也可以采用赋值的方式\n",
    "nn.init.ones_(b_hf)\n",
    "print(b_if)\n",
    "print(b_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], grad_fn=<SplitBackward>)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], grad_fn=<SplitBackward>)\n"
     ]
    }
   ],
   "source": [
    "b_ii, b_if_new, b_ic, b_io = net.bias_ih_l0.chunk(4, 0) #每个都是(hidden_size)\n",
    "print(b_if_new) #自动改变，因为内存相同\n",
    "b_hi, b_hf_new, b_hc, b_ho = net.bias_hh_l0.chunk(4, 0) #每个都是(hidden_size)\n",
    "print(b_hf_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #对各个gate分别初始化之后，重组:重组当然可以，但是没必要，对各个gate in_place的初始化会直接反应到net.weight_ih_l0\n",
    "# print(net.weight_ih_l0)\n",
    "# #.cat 和 .stack的区别在于 cat会增加现有维度的值,可以理解为拼接，stack会新加增加一个维度，可以理解为叠加\n",
    "# net.weight_ih_l0 = nn.Parameter(torch.cat((w_ii, w_if, w_ic, w_io), dim=0),\n",
    "#                                 requires_grad=True)\n",
    "# print(net.weight_ih_l0)\n",
    "# w_ii, w_if, w_ic, w_io = net.weight_ih_l0.chunk(4, 0)\n",
    "# print(w_if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU:不再赘述\n",
    "net = nn.GRU(100,128)\n",
    "w_ir, w_ii, w_in = net.weight_ih_l0.chunk(3, 0)\n",
    "w_hr, w_hi, w_hn = net.weight_hh_l0.chunk(3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([32, 10])\n",
      "weight_hh_l0 torch.Size([32, 8])\n",
      "bias_ih_l0 torch.Size([32])\n",
      "bias_hh_l0 torch.Size([32])\n",
      "weight_ih_l0_reverse torch.Size([32, 10])\n",
      "weight_hh_l0_reverse torch.Size([32, 8])\n",
      "bias_ih_l0_reverse torch.Size([32])\n",
      "bias_hh_l0_reverse torch.Size([32])\n",
      "weight_ih_l1 torch.Size([32, 16])\n",
      "weight_hh_l1 torch.Size([32, 8])\n",
      "bias_ih_l1 torch.Size([32])\n",
      "bias_hh_l1 torch.Size([32])\n",
      "weight_ih_l1_reverse torch.Size([32, 16])\n",
      "weight_hh_l1_reverse torch.Size([32, 8])\n",
      "bias_ih_l1_reverse torch.Size([32])\n",
      "bias_hh_l1_reverse torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "#看一个复杂点的例子：多层的会有层号，双向模型逆向有_reverse后缀\n",
    "net = nn.LSTM(10, 8, num_layers=2, bidirectional=True)#双层双向\n",
    "for name, params in net.named_parameters():\n",
    "    print(name, params.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
